{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cEpGkBAFzgMe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from catboost import CatBoostClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OYpweRHOzro_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbyNJrZc0EAr",
    "outputId": "48d3c0a7-1d24-46b5-d87c-c197ef9f6b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                       0\n",
       "patient_id                         0\n",
       "hospital_id                        0\n",
       "age                             4228\n",
       "bmi                             3429\n",
       "                               ...  \n",
       "solid_tumor_with_metastasis      715\n",
       "apache_3j_bodysystem            1662\n",
       "apache_2_bodysystem             1662\n",
       "Unnamed: 83                    91713\n",
       "hospital_death                     0\n",
       "Length: 85, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2_uR6nQ1Vsl",
    "outputId": "4e35dd9a-6a4f-4188-a18e-5925701862a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91713 entries, 0 to 91712\n",
      "Data columns (total 85 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   encounter_id                   91713 non-null  int64  \n",
      " 1   patient_id                     91713 non-null  int64  \n",
      " 2   hospital_id                    91713 non-null  int64  \n",
      " 3   age                            87485 non-null  float64\n",
      " 4   bmi                            88284 non-null  float64\n",
      " 5   elective_surgery               91713 non-null  int64  \n",
      " 6   ethnicity                      90318 non-null  object \n",
      " 7   gender                         91688 non-null  object \n",
      " 8   height                         90379 non-null  float64\n",
      " 9   icu_admit_source               91601 non-null  object \n",
      " 10  icu_id                         91713 non-null  int64  \n",
      " 11  icu_stay_type                  91713 non-null  object \n",
      " 12  icu_type                       91713 non-null  object \n",
      " 13  pre_icu_los_days               91713 non-null  float64\n",
      " 14  weight                         88993 non-null  float64\n",
      " 15  apache_2_diagnosis             90051 non-null  float64\n",
      " 16  apache_3j_diagnosis            90612 non-null  float64\n",
      " 17  apache_post_operative          91713 non-null  int64  \n",
      " 18  arf_apache                     90998 non-null  float64\n",
      " 19  gcs_eyes_apache                89812 non-null  float64\n",
      " 20  gcs_motor_apache               89812 non-null  float64\n",
      " 21  gcs_unable_apache              90676 non-null  float64\n",
      " 22  gcs_verbal_apache              89812 non-null  float64\n",
      " 23  heart_rate_apache              90835 non-null  float64\n",
      " 24  intubated_apache               90998 non-null  float64\n",
      " 25  map_apache                     90719 non-null  float64\n",
      " 26  resprate_apache                90479 non-null  float64\n",
      " 27  temp_apache                    87605 non-null  float64\n",
      " 28  ventilated_apache              90998 non-null  float64\n",
      " 29  d1_diasbp_max                  91548 non-null  float64\n",
      " 30  d1_diasbp_min                  91548 non-null  float64\n",
      " 31  d1_diasbp_noninvasive_max      90673 non-null  float64\n",
      " 32  d1_diasbp_noninvasive_min      90673 non-null  float64\n",
      " 33  d1_heartrate_max               91568 non-null  float64\n",
      " 34  d1_heartrate_min               91568 non-null  float64\n",
      " 35  d1_mbp_max                     91493 non-null  float64\n",
      " 36  d1_mbp_min                     91493 non-null  float64\n",
      " 37  d1_mbp_noninvasive_max         90234 non-null  float64\n",
      " 38  d1_mbp_noninvasive_min         90234 non-null  float64\n",
      " 39  d1_resprate_max                91328 non-null  float64\n",
      " 40  d1_resprate_min                91328 non-null  float64\n",
      " 41  d1_spo2_max                    91380 non-null  float64\n",
      " 42  d1_spo2_min                    91380 non-null  float64\n",
      " 43  d1_sysbp_max                   91554 non-null  float64\n",
      " 44  d1_sysbp_min                   91554 non-null  float64\n",
      " 45  d1_sysbp_noninvasive_max       90686 non-null  float64\n",
      " 46  d1_sysbp_noninvasive_min       90686 non-null  float64\n",
      " 47  d1_temp_max                    89389 non-null  float64\n",
      " 48  d1_temp_min                    89389 non-null  float64\n",
      " 49  h1_diasbp_max                  88094 non-null  float64\n",
      " 50  h1_diasbp_min                  88094 non-null  float64\n",
      " 51  h1_diasbp_noninvasive_max      84363 non-null  float64\n",
      " 52  h1_diasbp_noninvasive_min      84363 non-null  float64\n",
      " 53  h1_heartrate_max               88923 non-null  float64\n",
      " 54  h1_heartrate_min               88923 non-null  float64\n",
      " 55  h1_mbp_max                     87074 non-null  float64\n",
      " 56  h1_mbp_min                     87074 non-null  float64\n",
      " 57  h1_mbp_noninvasive_max         82629 non-null  float64\n",
      " 58  h1_mbp_noninvasive_min         82629 non-null  float64\n",
      " 59  h1_resprate_max                87356 non-null  float64\n",
      " 60  h1_resprate_min                87356 non-null  float64\n",
      " 61  h1_spo2_max                    87528 non-null  float64\n",
      " 62  h1_spo2_min                    87528 non-null  float64\n",
      " 63  h1_sysbp_max                   88102 non-null  float64\n",
      " 64  h1_sysbp_min                   88102 non-null  float64\n",
      " 65  h1_sysbp_noninvasive_max       84372 non-null  float64\n",
      " 66  h1_sysbp_noninvasive_min       84372 non-null  float64\n",
      " 67  d1_glucose_max                 85906 non-null  float64\n",
      " 68  d1_glucose_min                 85906 non-null  float64\n",
      " 69  d1_potassium_max               82128 non-null  float64\n",
      " 70  d1_potassium_min               82128 non-null  float64\n",
      " 71  apache_4a_hospital_death_prob  83766 non-null  float64\n",
      " 72  apache_4a_icu_death_prob       83766 non-null  float64\n",
      " 73  aids                           90998 non-null  float64\n",
      " 74  cirrhosis                      90998 non-null  float64\n",
      " 75  diabetes_mellitus              90998 non-null  float64\n",
      " 76  hepatic_failure                90998 non-null  float64\n",
      " 77  immunosuppression              90998 non-null  float64\n",
      " 78  leukemia                       90998 non-null  float64\n",
      " 79  lymphoma                       90998 non-null  float64\n",
      " 80  solid_tumor_with_metastasis    90998 non-null  float64\n",
      " 81  apache_3j_bodysystem           90051 non-null  object \n",
      " 82  apache_2_bodysystem            90051 non-null  object \n",
      " 83  Unnamed: 83                    0 non-null      float64\n",
      " 84  hospital_death                 91713 non-null  int64  \n",
      "dtypes: float64(71), int64(7), object(7)\n",
      "memory usage: 59.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WuiKVRst1i3j"
   },
   "outputs": [],
   "source": [
    "df.drop([\"encounter_id\" ,\"patient_id\" ,\"hospital_id\",\"Unnamed: 83\", ],axis =1, inplace=True) # Not relevant to predict if a patient died or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdlqnDDn1kkn",
    "outputId": "8989e055-b8ba-4719-86bc-cdc49e2b801a"
   },
   "outputs": [],
   "source": [
    "# Dealing with numerical columns\n",
    "Num=[]\n",
    "for col in df.columns:\n",
    "    if (df[col].dtype==int)or (df[col].dtype==float):\n",
    "        Num.append(col)\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in Num :\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        \n",
    "# Dealing with categorical columns\n",
    "categorical=[]\n",
    "for col in df.columns:\n",
    "    if  (df[col].dtype==object):\n",
    "        categorical.append(col)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in categorical:\n",
    "        df[col].fillna(df[col].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWZZ3WLb4KUz",
    "outputId": "b258b533-1189-4e22-9976-70b72671e99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\arind\\anaconda3\\lib\\site-packages (2.5.1.post0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arind\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arind\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BarcY5Ee3--X"
   },
   "outputs": [],
   "source": [
    "from category_encoders import CountEncoder\n",
    "CE = CountEncoder(normalize=True, cols=categorical)\n",
    "data = CE.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wRyY_hDu4Q7T"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "RS = RobustScaler()\n",
    "scale = RS.fit_transform(data)\n",
    "data = pd.DataFrame(scale, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hbaNI4W75JGC"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     16756\n",
      "         1.0       0.71      0.27      0.39      1587\n",
      "\n",
      "    accuracy                           0.93     18343\n",
      "   macro avg       0.82      0.63      0.68     18343\n",
      "weighted avg       0.92      0.93      0.91     18343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 15, 20, 25, 30],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 800, 1400, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pprint \n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 5)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pp = pprint.PrettyPrinter(width=41, compact=True)\n",
    "pp.pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 800, 1400, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_random.predict(X_test)\n",
    "print(rf_random.best_estimator_)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 800, 1400, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=1400)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     16756\n",
      "         1.0       0.62      0.22      0.33      1587\n",
      "\n",
      "    accuracy                           0.92     18343\n",
      "   macro avg       0.78      0.61      0.64     18343\n",
      "weighted avg       0.90      0.92      0.90     18343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = rf_random.predict(X_test)\n",
    "print(rf_random.best_estimator_)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.7) # I tried 0.5 and 0.8, worser results\n",
    "X_train = pca.fit_transform(X_train, y_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 800, 1400, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=1400)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     16756\n",
      "         1.0       0.67      0.25      0.36      1587\n",
      "\n",
      "    accuracy                           0.92     18343\n",
      "   macro avg       0.80      0.62      0.66     18343\n",
      "weighted avg       0.91      0.92      0.91     18343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = rf_random.predict(X_test)\n",
    "print(rf_random.best_estimator_)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
